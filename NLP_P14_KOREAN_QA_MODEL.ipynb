{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14-6. 프로젝트: 한국어 QA 모델 만들기\n",
    "\n",
    "Date: 05112021\n",
    "\n",
    "keyword\n",
    "#bAbI #end-to-end memory network\n",
    "\n",
    "data\n",
    ": korean version bAbI dataset\n",
    "\n",
    "purpose\n",
    ": KOREAN QA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import tarfile\n",
    "from nltk import FreqDist\n",
    "from functools import reduce\n",
    "import os\n",
    "import re\n",
    "import konlpy\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ckonlpy.tag import Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import tensorflow as tf\n",
    "\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경에 맞게 경로 적절히 수정\n",
    "home_dir = os.getenv('HOME')+'/aiffel/aiffel_exp_data'\n",
    "DATA_DIR = home_dir + '/data'\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train_kor.txt\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test_kor.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 필웅이는 화장실로 갔습니다.\n",
      "2 은경이는 복도로 이동했습니다.\n",
      "3 필웅이는 어디야? \t화장실\t1\n",
      "4 수종이는 복도로 복귀했습니다.\n",
      "5 경임이는 정원으로 갔습니다.\n",
      "6 수종이는 어디야? \t복도\t4\n",
      "7 은경이는 사무실로 갔습니다.\n",
      "8 경임이는 화장실로 뛰어갔습니다.\n",
      "9 수종이는 어디야? \t복도\t4\n",
      "10 필웅이는 복도로 갔습니다.\n",
      "11 수종이는 사무실로 가버렸습니다.\n",
      "12 수종이는 어디야? \t사무실\t11\n",
      "13 은경이는 정원으로 복귀했습니다.\n",
      "14 은경이는 침실로 갔습니다.\n",
      "15 경임이는 어디야? \t화장실\t8\n",
      "1 경임이는 사무실로 가버렸습니다.\n",
      "2 경임이는 화장실로 이동했습니다.\n",
      "3 경임이는 어디야? \t화장실\t2\n",
      "4 필웅이는 침실로 이동했습니다.\n",
      "5 수종이는 복도로 갔습니다.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "lines = open(TRAIN_FILE , \"rb\")  # open: opens a file in text format by default. \n",
    "# rb:opens the file in binary format for reading \n",
    "for line in lines:\n",
    "    line = line.decode(\"utf-8\").strip()\n",
    "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
    "    i = i + 1\n",
    "    print(line)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir):\n",
    "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
    "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
    "    lines = open(dir, \"rb\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.decode(\"utf-8\") # b' 제거\n",
    "        line = line.strip() # '\\n' 제거\n",
    "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
    "        # 여기까지는 모든 줄에 적용되는 전처리\n",
    "\n",
    "        if int(idx) == 1:\n",
    "            story_temp = []\n",
    "        \n",
    "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
    "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
    "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "        else: # 현재 읽는 줄이 스토리인 경우\n",
    "            story_temp.append(text) # 임시 저장\n",
    "\n",
    "    lines.close()\n",
    "    return stories, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(TRAIN_FILE)\n",
    "test_data = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
    "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_stories))\n",
    "print(len(train_questions))\n",
    "print(len(train_answers))\n",
    "print(len(test_stories))\n",
    "print(len(test_questions))\n",
    "print(len(test_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['필웅이는 화장실로 가버렸습니다.', '경임이는 부엌으로 갔습니다.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stories[2400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['필웅이는 어디야? ', '수종이는 어디야? ', '수종이는 어디야? ', '수종이는 어디야? ', '경임이는 어디야? ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['화장실', '복도', '복도', '사무실', '화장실']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma=Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['이것', '이', '왜', '안되', '는', '거', '야', '!!']\n"
     ]
    }
   ],
   "source": [
    "print(kkma.morphs('이게 왜 안되는거야!!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj54/anaconda3/envs/aiffel/lib/python3.7/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['은경이', '는', '사무실', '로', '갔습니다', '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 예시 코드\n",
    "from ckonlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "twitter.add_dictionary('은경이', 'Noun')\n",
    "twitter.morphs('은경이는 사무실로 갔습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return twitter.morphs(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    counter = FreqDist()\n",
    "    \n",
    "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    # 각 샘플의 길이를 저장하는 리스트\n",
    "    story_len = []\n",
    "    question_len = []\n",
    "    \n",
    "    for stories, questions, answers in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
    "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
    "            for word in stories: # 단어 집합에 단어 추가\n",
    "                counter[word] += 1\n",
    "        for question in questions:\n",
    "            question = tokenize(question)\n",
    "            question_len.append(len(question))\n",
    "            for word in question:\n",
    "                counter[word] += 1\n",
    "        for answer in answers:\n",
    "            answer = tokenize(answer)\n",
    "            for word in answer:\n",
    "                counter[word] += 1\n",
    "\n",
    "    # 단어장 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석 후 불용어 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 함수를 사용하여 단어장과 가장 긴 샘플의 길이를 리턴 \n",
    "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'는': 1, '.': 2, '로': 3, '이': 4, '했습니다': 5, '으로': 6, '경': 7, '임': 8, '은경이': 9, '수종': 10, '필웅이': 11, '이동': 12, '가버렸습니다': 13, '뛰어갔습니다': 14, '복귀': 15, '화장실': 16, '정원': 17, '복도': 18, '갔습니다': 19, '사무실': 20, '부엌': 21, '침실': 22, '어디': 23, '야': 24, '?': 25}\n"
     ]
    }
   ],
   "source": [
    "# 단어장 출력\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩을 고려하여 단어장 +1\n",
    "vocab_size = len(word2idx) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스토리의 최대 길이 : 82\n",
      "질문의 최대 길이 : 7\n"
     ]
    }
   ],
   "source": [
    "print('스토리의 최대 길이 :',story_max_len)\n",
    "print('질문의 최대 길이 :',question_max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
    "        xq = [word2idx[w] for w in tokenize(question)]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(word2idx[answer])\n",
    "\n",
    "    # 스토리와 질문은 각각의 최대 길이로 패딩\n",
    "    # 정답은 원-핫 인코딩\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           to_categorical(Y, num_classes=len(word2idx) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 82) (10000, 7) (10000, 26) (1000, 82) (1000, 7) (1000, 26)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한국어에서의 모델 정확도 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 에포크 횟수\n",
    "train_epochs = 120\n",
    "# 배치 크기\n",
    "batch_size = 32\n",
    "# 임베딩 크기\n",
    "embed_size = 50\n",
    "# LSTM의 크기\n",
    "lstm_size = 64\n",
    "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
    "dropout_rate = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stories : KerasTensor(type_spec=TensorSpec(shape=(None, 82), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\")\n",
      "Question: KerasTensor(type_spec=TensorSpec(shape=(None, 7), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\")\n"
     ]
    }
   ],
   "source": [
    "# 입력을 담아두는 변수 정의\n",
    "input_sequence = Input((story_max_len,))\n",
    "question = Input((question_max_len,))\n",
    " \n",
    "print('Stories :', input_sequence)\n",
    "print('Question:', question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size))\n",
    "input_encoder_m.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, embed_size) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
    " \n",
    "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
    "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=question_max_len))\n",
    "input_encoder_c.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embed_size,\n",
    "                               input_length=question_max_len))\n",
    "question_encoder.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, question_max_len, embed_size) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input encoded m KerasTensor(type_spec=TensorSpec(shape=(None, 82, 50), dtype=tf.float32, name=None), name='sequential_6/dropout_8/Identity:0', description=\"created by layer 'sequential_6'\")\n",
      "Input encoded c KerasTensor(type_spec=TensorSpec(shape=(None, 82, 7), dtype=tf.float32, name=None), name='sequential_7/dropout_9/Identity:0', description=\"created by layer 'sequential_7'\")\n",
      "Question encoded KerasTensor(type_spec=TensorSpec(shape=(None, 7, 50), dtype=tf.float32, name=None), name='sequential_8/dropout_10/Identity:0', description=\"created by layer 'sequential_8'\")\n"
     ]
    }
   ],
   "source": [
    "# 실질적인 임베딩 과정\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "print('Input encoded m', input_encoded_m)\n",
    "print('Input encoded c', input_encoded_c)\n",
    "print('Question encoded', question_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match shape KerasTensor(type_spec=TensorSpec(shape=(None, 82, 7), dtype=tf.float32, name=None), name='activation_4/truediv:0', description=\"created by layer 'activation_4'\")\n"
     ]
    }
   ],
   "source": [
    "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
    "# 유사도는 내적을 사용한다.\n",
    "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response shape KerasTensor(type_spec=TensorSpec(shape=(None, 7, 82), dtype=tf.float32, name=None), name='permute_2/transpose:0', description=\"created by layer 'permute_2'\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 매칭 유사도 행렬과 질문에 대한 임베딩을 더한다.\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, question_max_len)\n",
    "response = Permute((2, 1))(response)  # (samples, question_max_len, story_maxlen)\n",
    "print('Response shape', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer shape KerasTensor(type_spec=TensorSpec(shape=(None, 7, 132), dtype=tf.float32, name=None), name='concatenate_2/concat:0', description=\"created by layer 'concatenate_2'\")\n"
     ]
    }
   ],
   "source": [
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    " \n",
    "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(dropout_rate)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 3s 5ms/step - loss: 2.0718 - acc: 0.1630 - val_loss: 1.7612 - val_acc: 0.2990\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.7175 - acc: 0.2501 - val_loss: 1.6005 - val_acc: 0.3430\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.6011 - acc: 0.3268 - val_loss: 1.5927 - val_acc: 0.3500\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.5165 - acc: 0.3804 - val_loss: 1.4716 - val_acc: 0.4300\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.4857 - acc: 0.4101 - val_loss: 1.4326 - val_acc: 0.4520\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.4338 - acc: 0.4604 - val_loss: 1.3940 - val_acc: 0.4890\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.3686 - acc: 0.4868 - val_loss: 1.3830 - val_acc: 0.4570\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3193 - acc: 0.5095 - val_loss: 1.3092 - val_acc: 0.5100\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2903 - acc: 0.5163 - val_loss: 1.2837 - val_acc: 0.5170\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2694 - acc: 0.5132 - val_loss: 1.2710 - val_acc: 0.5240\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2449 - acc: 0.5238 - val_loss: 1.2353 - val_acc: 0.5250\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2157 - acc: 0.5305 - val_loss: 1.2187 - val_acc: 0.5400\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2015 - acc: 0.5432 - val_loss: 1.2153 - val_acc: 0.5360\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1668 - acc: 0.5657 - val_loss: 1.1886 - val_acc: 0.5500\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1357 - acc: 0.5752 - val_loss: 1.1793 - val_acc: 0.5600\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1283 - acc: 0.5769 - val_loss: 1.1462 - val_acc: 0.5760\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0729 - acc: 0.5983 - val_loss: 1.1356 - val_acc: 0.5600\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0851 - acc: 0.5820 - val_loss: 1.1318 - val_acc: 0.5750\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0406 - acc: 0.6102 - val_loss: 1.1110 - val_acc: 0.5770\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0698 - acc: 0.5983 - val_loss: 1.1376 - val_acc: 0.5810\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0329 - acc: 0.6139 - val_loss: 1.1314 - val_acc: 0.5990\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0259 - acc: 0.6148 - val_loss: 1.1139 - val_acc: 0.5880\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0074 - acc: 0.6269 - val_loss: 1.1027 - val_acc: 0.5970\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.9849 - acc: 0.6327 - val_loss: 1.0991 - val_acc: 0.5980\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.9599 - acc: 0.6403 - val_loss: 1.0652 - val_acc: 0.6120\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.9299 - acc: 0.6536 - val_loss: 1.0562 - val_acc: 0.6170\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.9127 - acc: 0.6667 - val_loss: 1.0490 - val_acc: 0.6260\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.8623 - acc: 0.6929 - val_loss: 0.9652 - val_acc: 0.6530\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.7927 - acc: 0.7206 - val_loss: 0.8214 - val_acc: 0.7110\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6870 - acc: 0.7637 - val_loss: 0.7604 - val_acc: 0.7370\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6327 - acc: 0.7836 - val_loss: 0.7408 - val_acc: 0.7300\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5864 - acc: 0.7984 - val_loss: 0.6828 - val_acc: 0.7500\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5803 - acc: 0.7945 - val_loss: 0.6779 - val_acc: 0.7580\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5402 - acc: 0.8125 - val_loss: 0.6779 - val_acc: 0.7600\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5206 - acc: 0.8096 - val_loss: 0.6276 - val_acc: 0.7770\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4990 - acc: 0.8230 - val_loss: 0.6351 - val_acc: 0.7700\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4625 - acc: 0.8333 - val_loss: 0.6042 - val_acc: 0.7820\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4599 - acc: 0.8320 - val_loss: 0.6048 - val_acc: 0.7850\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4430 - acc: 0.8401 - val_loss: 0.5726 - val_acc: 0.7940\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4214 - acc: 0.8494 - val_loss: 0.5343 - val_acc: 0.8020\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3850 - acc: 0.8593 - val_loss: 0.4957 - val_acc: 0.8210\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3556 - acc: 0.8708 - val_loss: 0.4866 - val_acc: 0.8140\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3456 - acc: 0.8758 - val_loss: 0.4912 - val_acc: 0.8210\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3246 - acc: 0.8865 - val_loss: 0.4853 - val_acc: 0.8210\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3253 - acc: 0.8801 - val_loss: 0.4736 - val_acc: 0.8310\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3104 - acc: 0.8922 - val_loss: 0.4460 - val_acc: 0.8390\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2885 - acc: 0.8967 - val_loss: 0.4702 - val_acc: 0.8340\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2849 - acc: 0.9005 - val_loss: 0.4543 - val_acc: 0.8370\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2655 - acc: 0.9032 - val_loss: 0.4406 - val_acc: 0.8360\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2639 - acc: 0.9049 - val_loss: 0.4297 - val_acc: 0.8470\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2544 - acc: 0.9100 - val_loss: 0.4472 - val_acc: 0.8450\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2580 - acc: 0.9093 - val_loss: 0.4731 - val_acc: 0.8420\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2444 - acc: 0.9100 - val_loss: 0.4303 - val_acc: 0.8520\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2307 - acc: 0.9181 - val_loss: 0.4950 - val_acc: 0.8370\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2215 - acc: 0.9200 - val_loss: 0.4535 - val_acc: 0.8450\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2114 - acc: 0.9231 - val_loss: 0.4598 - val_acc: 0.8520\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2145 - acc: 0.9250 - val_loss: 0.4856 - val_acc: 0.8430\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2112 - acc: 0.9234 - val_loss: 0.4765 - val_acc: 0.8450\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2019 - acc: 0.9238 - val_loss: 0.4589 - val_acc: 0.8470\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1853 - acc: 0.9359 - val_loss: 0.4595 - val_acc: 0.8580\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1817 - acc: 0.9369 - val_loss: 0.4934 - val_acc: 0.8520\n",
      "Epoch 62/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1689 - acc: 0.9393 - val_loss: 0.4944 - val_acc: 0.8450\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1695 - acc: 0.9377 - val_loss: 0.5069 - val_acc: 0.8430\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1748 - acc: 0.9415 - val_loss: 0.4945 - val_acc: 0.8490\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1701 - acc: 0.9380 - val_loss: 0.4651 - val_acc: 0.8580\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1627 - acc: 0.9459 - val_loss: 0.4573 - val_acc: 0.8560\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1515 - acc: 0.9479 - val_loss: 0.4869 - val_acc: 0.8460\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1616 - acc: 0.9431 - val_loss: 0.5425 - val_acc: 0.8410\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1523 - acc: 0.9449 - val_loss: 0.4839 - val_acc: 0.8510\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1498 - acc: 0.9488 - val_loss: 0.4570 - val_acc: 0.8610\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1396 - acc: 0.9515 - val_loss: 0.5097 - val_acc: 0.8550\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1388 - acc: 0.9502 - val_loss: 0.4763 - val_acc: 0.8610\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1286 - acc: 0.9569 - val_loss: 0.4711 - val_acc: 0.8610\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1205 - acc: 0.9598 - val_loss: 0.4828 - val_acc: 0.8640\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1254 - acc: 0.9589 - val_loss: 0.4974 - val_acc: 0.8610\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1119 - acc: 0.9612 - val_loss: 0.4769 - val_acc: 0.8570\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1123 - acc: 0.9611 - val_loss: 0.5018 - val_acc: 0.8620\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1133 - acc: 0.9591 - val_loss: 0.4974 - val_acc: 0.8590\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1143 - acc: 0.9606 - val_loss: 0.4802 - val_acc: 0.8600\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1069 - acc: 0.9644 - val_loss: 0.4527 - val_acc: 0.8700\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1022 - acc: 0.9647 - val_loss: 0.4799 - val_acc: 0.8720\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1072 - acc: 0.9629 - val_loss: 0.4563 - val_acc: 0.8830\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1039 - acc: 0.9659 - val_loss: 0.4610 - val_acc: 0.8790\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1012 - acc: 0.9651 - val_loss: 0.4964 - val_acc: 0.8740\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1027 - acc: 0.9673 - val_loss: 0.4675 - val_acc: 0.8810\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0824 - acc: 0.9730 - val_loss: 0.4923 - val_acc: 0.8750\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0905 - acc: 0.9706 - val_loss: 0.4713 - val_acc: 0.8790\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0819 - acc: 0.9724 - val_loss: 0.4576 - val_acc: 0.8780\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0713 - acc: 0.9754 - val_loss: 0.4774 - val_acc: 0.8800\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0831 - acc: 0.9715 - val_loss: 0.4691 - val_acc: 0.8810\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0733 - acc: 0.9735 - val_loss: 0.5082 - val_acc: 0.8770\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0736 - acc: 0.9756 - val_loss: 0.4873 - val_acc: 0.8780\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0801 - acc: 0.9759 - val_loss: 0.4410 - val_acc: 0.8980\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0703 - acc: 0.9778 - val_loss: 0.4503 - val_acc: 0.8890\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0736 - acc: 0.9752 - val_loss: 0.4840 - val_acc: 0.8850\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0618 - acc: 0.9801 - val_loss: 0.4516 - val_acc: 0.8850\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0683 - acc: 0.9772 - val_loss: 0.4491 - val_acc: 0.8950\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0753 - acc: 0.9763 - val_loss: 0.4921 - val_acc: 0.8860\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0752 - acc: 0.9742 - val_loss: 0.4939 - val_acc: 0.8890\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0594 - acc: 0.9809 - val_loss: 0.4957 - val_acc: 0.8910\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0771 - acc: 0.9727 - val_loss: 0.4715 - val_acc: 0.8900\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0548 - acc: 0.9812 - val_loss: 0.4559 - val_acc: 0.8930\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0466 - acc: 0.9854 - val_loss: 0.4545 - val_acc: 0.8950\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0560 - acc: 0.9838 - val_loss: 0.5140 - val_acc: 0.8880\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0556 - acc: 0.9806 - val_loss: 0.5110 - val_acc: 0.8920\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0581 - acc: 0.9834 - val_loss: 0.4905 - val_acc: 0.8870\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0536 - acc: 0.9834 - val_loss: 0.5085 - val_acc: 0.8970\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0581 - acc: 0.9840 - val_loss: 0.4821 - val_acc: 0.8910\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0535 - acc: 0.9822 - val_loss: 0.4840 - val_acc: 0.9040\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0503 - acc: 0.9840 - val_loss: 0.4829 - val_acc: 0.8980\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0554 - acc: 0.9823 - val_loss: 0.4905 - val_acc: 0.8950\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0525 - acc: 0.9823 - val_loss: 0.5214 - val_acc: 0.8880\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0488 - acc: 0.9853 - val_loss: 0.4836 - val_acc: 0.9010\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0505 - acc: 0.9839 - val_loss: 0.4947 - val_acc: 0.8950\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0517 - acc: 0.9845 - val_loss: 0.4595 - val_acc: 0.8920\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0518 - acc: 0.9831 - val_loss: 0.4928 - val_acc: 0.9020\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0454 - acc: 0.9858 - val_loss: 0.4963 - val_acc: 0.9000\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0446 - acc: 0.9826 - val_loss: 0.4834 - val_acc: 0.8920\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0425 - acc: 0.9853 - val_loss: 0.5506 - val_acc: 0.8830\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0458 - acc: 0.9842 - val_loss: 0.4853 - val_acc: 0.9090\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    " \n",
    "# 테스트 데이터를 검증 데이터로 사용하면서 모델 훈련 시작\n",
    "history = model.fit([Xstrain, Xqtrain],\n",
    "         Ytrain, batch_size, train_epochs,\n",
    "         validation_data=([Xstest, Xqtest], Ytest))\n",
    " \n",
    "# 훈련 후에는 모델 저장\n",
    "model_path = os.getenv('HOME')+'/aiffel/aiffel_nlp_ex/model_ko.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4853 - acc: 0.9090\n",
      "\n",
      " 테스트 정확도: 0.9090\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy and loss plot\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# labels\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "\n",
    "# get predictions\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "ytest_ = np.argmax(Ytest_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NUM_DISPLAY = 30\n",
    "\n",
    "# print(\"{:18}|{:5}|{}\".format(\"질문\", \"실제값\", \"예측값\"))\n",
    "# print(39 * \"-\")\n",
    "\n",
    "# for i in range(NUM_DISPLAY):\n",
    "#     question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n",
    "#     label = idx2word[ytest[i]]\n",
    "#     prediction = idx2word[ytest_[i]]\n",
    "#     print(\"{:20}: {:7} {}\".format(question, label, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "루브릭\n",
    "평가문항\t상세기준\t결과\n",
    "1. 한국어의 특성에 알맞게 전처리가 진행되었다.\t한국어 특성에 따른 토큰화, 임베딩을 거쳐 데이터셋이 적절히 구성되었다.\t\n",
    "2. 메모리 네트워크가 정상적으로 구현되어 학습이 안정적으로 진행되었다.\tvalidation loss가 안정적으로 수렴하는 것을 확인하고 이를 시각화하였다.\t\n",
    "3. 메모리 네트워크를 통해 한국어 bAbI 태스크의 높은 정확도를 달성하였다.\t추론 태스크의 테스트 정확도가 90% 이상 달성하였다.\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

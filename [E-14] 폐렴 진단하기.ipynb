{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "increasing-cookbook",
   "metadata": {},
   "source": [
    "# [E-14] 폐렴 진단하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-fancy",
   "metadata": {},
   "source": [
    "# 목차\n",
    "\n",
    "Step 1. 실험환경 Set-up\n",
    "\n",
    "Step 2. 데이터 준비하기\n",
    "\n",
    "Step 3. 데이터 시각화\n",
    "\n",
    "Step 4. CNN 모델\n",
    "\n",
    "Step 5. 데이터 imbalance 처리\n",
    "\n",
    "Step 6. 모델 훈련\n",
    "\n",
    "Step 7. 결과 확인과 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-absorption",
   "metadata": {},
   "source": [
    "# 루브릭\n",
    "\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "평가문항\n",
    "\n",
    "1. 의료영상을 처리하는 CNN 기반 딥러닝 모델이 잘 구현되었다.\n",
    "모델 학습이 안정적으로 수렴하는 것을 시각화를 통해 확인하였다.\n",
    "\n",
    "\n",
    "2. 데이터 준비, 모델구성 등의 과정의 다양한 실험이 체계적으로 수행되었다.\n",
    "regularization, augmentation 등의 기법의 사용 여부에 따른 모델 성능 측정이 ablation study 형태로 체계적으로 수행되었다.\n",
    "\n",
    "\n",
    "3. 실습코드를 잘 개선하여 폐렴 검출 정확도가 추가로 향상되었다.\n",
    "\tAccuracy 기준 85%에 도달하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-ethiopia",
   "metadata": {},
   "source": [
    "# Step 1. 실험환경 Set-up\n",
    " Batch size, Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "creative-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re    # 정규표현식 관련된 작업에 필요한 패키지\n",
    "import os    # I/O 관련된 작업에 필요한 패키지 \n",
    "import pandas as pd     # 데이터 전처리 관련된 작업에 필요한 패키지\n",
    "import numpy as np      # 데이터 array 작업에 필요한 패키지\n",
    "import tensorflow as tf  # 딥러닝 관련된 작업에 필요한 패키지\n",
    "import matplotlib.pyplot as plt    # 데이터 시각화에 관련된 작업에 필요한 패키지\n",
    "from sklearn.model_selection import train_test_split  # 데이터 전처리에 필요한 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worst-haiti",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj54/aiffel\n"
     ]
    }
   ],
   "source": [
    "# 네트워크가 스스로 설정하고 데이터셋을 잘 불러올 수 있게 결정하도록 하는 것\n",
    "# 많은 양의 데이터를 처리할때 로드를 자동으로 해줘서 속도가 빨라진다.\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# 데이터 ROOT 경로 변수\n",
    "ROOT_PATH = os.path.join(os.getenv('HOME'), 'aiffel')\n",
    "\n",
    "# BATCH_SIZE 변수 #변경가능\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# X-RAY 이미지 사이즈 변수\n",
    "IMAGE_SIZE = [300, 300] #변경가능하나 원본이미지(406,305) 크기보면서 적절히 조절\n",
    "\n",
    "# EPOCH 크기 변수 #변경가능\n",
    "EPOCHS = 30\n",
    "\n",
    "print(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-gateway",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ranking-knight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5216\n",
      "624\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "train_filenames = tf.io.gfile.glob(str(ROOT_PATH + '/aiffel_exp_data/E-14_exp_data/chest_xray/train/*/*'))\n",
    "test_filenames = tf.io.gfile.glob(str(ROOT_PATH + '/aiffel_exp_data/E-14_exp_data/chest_xray/test/*/*'))\n",
    "val_filenames = tf.io.gfile.glob(str(ROOT_PATH + '/aiffel_exp_data/E-14_exp_data/chest_xray/val/*/*'))\n",
    "\n",
    "print(len(train_filenames))\n",
    "print(len(test_filenames))\n",
    "print(len(val_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "overhead-tower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4185\n",
      "1047\n"
     ]
    }
   ],
   "source": [
    "filenames = tf.io.gfile.glob(str(ROOT_PATH + '/aiffel_exp_data/E-14_exp_data/chest_xray/train/*/*'))\n",
    "filenames.extend(tf.io.gfile.glob(str(ROOT_PATH + '/aiffel_exp_data/E-14_exp_data/chest_xray/val/*/*')))\n",
    "\n",
    "# train, test(val) dataset으로 분할. test_size에 0.2는 20%롤 의미함.\n",
    "train_filenames, val_filenames = train_test_split(filenames, test_size=0.2)\n",
    "\n",
    "print(len(train_filenames))\n",
    "print(len(val_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "peripheral-basement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal images count in training set: 1096\n",
      "Pneumonia images count in training set: 3089\n"
     ]
    }
   ],
   "source": [
    "COUNT_NORMAL = len([filename for filename in train_filenames if \"NORMAL\" in filename])\n",
    "print(\"Normal images count in training set: \" + str(COUNT_NORMAL))\n",
    "\n",
    "COUNT_PNEUMONIA = len([filename for filename in train_filenames if \"PNEUMONIA\" in filename])\n",
    "print(\"Pneumonia images count in training set: \" + str(COUNT_PNEUMONIA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handled-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습시킬때 배치처리 작업을 더 효율적으로 하기 위해 tensor로 바꾼다\n",
    "train_list_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\n",
    "val_list_ds = tf.data.Dataset.from_tensor_slices(val_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fallen-intellectual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련이미지 갯수: 4185\n",
      "검증이미지 갯수: 1047\n"
     ]
    }
   ],
   "source": [
    "TRAIN_IMG_COUNT = tf.data.experimental.cardinality(train_list_ds).numpy()\n",
    "print(\"훈련이미지 갯수: \" + str(TRAIN_IMG_COUNT))\n",
    "\n",
    "VAL_IMG_COUNT = tf.data.experimental.cardinality(val_list_ds).numpy()\n",
    "print(\"검증이미지 갯수: \" + str(VAL_IMG_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "burning-recognition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PNEUMONIA' 'NORMAL']\n"
     ]
    }
   ],
   "source": [
    "#train 안에 라벨은 2개! 안에 데이터는 없음\n",
    "#os.path.sep(os별 파일 경로를 나눈 구간별로 split한다.)\n",
    "# 0이 뭔가?\n",
    "\n",
    "CLASS_NAMES = np.array([str(tf.strings.split(item, os.path.sep)[-1].numpy())[2:-1]\n",
    "                        for item in tf.io.gfile.glob(str(ROOT_PATH + \"/aiffel_exp_data/E-14_exp_data/chest_xray/train/*\"))])\n",
    "print(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "trained-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2] == \"PNEUMONIA\"   # 폐렴이면 양성(True), 노말이면 음성(False)를 리턴하게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "gothic-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    img = tf.image.decode_jpeg(img, channels=3)          # 이미지를 uint8 tensor로 바꾼다.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32) # img를 범위 [0,1]의 float32 데이터 타입으로 바꾼다.\n",
    "    return tf.image.resize(img, IMAGE_SIZE)   # img의 이미지 사이즈를 IMAGE_SIZE에서 지정한 사이즈로 수정한다.\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)      #폐렴이면 양성, 정상이면 음성을 나타내는 함수를 가져온다.\n",
    "    img = tf.io.read_file(file_path)  #이미지를 읽어오고\n",
    "    img = decode_img(img)             #이미지 사이즈를 통일 한 후 크기를 줄인다. \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "confident-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "polished-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# argumentation\n",
    "\n",
    "def augment(image,label):\n",
    "    image = tf.image.random_flip_left_right(image)  # 랜덤하게 좌우를 반전합니다.\n",
    "    return image,label\n",
    "\n",
    "def prepare_for_training(ds, shuffle_buffer_size=1000):\n",
    "    # augment 적용 부분이 배치처리 함수에 추가되었습니다.\n",
    "    ds = ds.map(\n",
    "            augment,       # augment 함수 적용\n",
    "            num_parallel_calls=2\n",
    "        )\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "train_ds = prepare_for_training(train_ds)\n",
    "val_ds = prepare_for_training(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "automatic-stomach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (16, 300, 300, 3)\n",
      "Label:  [ True False False  True False False False False  True  True False  True\n",
      " False  True  True  True]\n",
      "Image shape:  (16, 300, 300, 3)\n",
      "Label:  [ True False False  True  True False  True False  True  True False False\n",
      "  True False  True  True]\n",
      "Image shape:  (16, 300, 300, 3)\n",
      "Label:  [False False  True False  True False False  True  True  True  True  True\n",
      "  True  True False  True]\n",
      "Image shape:  (16, 300, 300, 3)\n",
      "Label:  [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False False  True False]\n",
      "Image shape:  (16, 300, 300, 3)\n",
      "Label:  [ True  True  True  True  True  True  True  True False False False  True\n",
      "  True False  True  True]\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_ds.take(5):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "outstanding-ecology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624\n"
     ]
    }
   ],
   "source": [
    "#test셋도 동일하게 진행\n",
    "\n",
    "test_list_ds = tf.data.Dataset.list_files(str(ROOT_PATH + '/aiffel_exp_data/E-14_exp_data/chest_xray/test/*/*'))\n",
    "TEST_IMAGE_COUNT = tf.data.experimental.cardinality(test_list_ds).numpy()\n",
    "test_ds = test_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)\n",
    "\n",
    "print(TEST_IMAGE_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "vocational-authorization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (16, 300, 300, 3)\n",
      "Label:  [ True False  True  True  True  True  True False False False False  True\n",
      "  True False  True  True]\n"
     ]
    }
   ],
   "source": [
    "for image, label in test_ds.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rural-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, shuffle_buffer_size=1000):\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    ds = ds.repeat() #epoch를 진행할때 자동으로 데이터를 맞춰준다.\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE) #학습데이터를 나눠서 읽어온다. 1번째가 학습하는 동안 두번째가 대기중 \n",
    "\n",
    "    return ds\n",
    "\n",
    "train_ds = prepare_for_training(train_ds)\n",
    "val_ds = prepare_for_training(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-warren",
   "metadata": {},
   "source": [
    "# Step 3. 데이터 시각화\n",
    "\n",
    "train에 있는 batch 중 첫번째 배치를 추출한다. \n",
    "배치안에 있는 img와 label을 나눈다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_ds))\n",
    "#train ds에 있는 것을 반복해서 한개씩 읽어서 나타낸다.\n",
    "\n",
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(16):  #batch size가 16이라서 16개!\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        if label_batch[n]:\n",
    "            plt.title(\"PNEUMONIA\")\n",
    "        else:\n",
    "            plt.title(\"NORMAL\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-equilibrium",
   "metadata": {},
   "source": [
    "# Step 4. CNN 모델링\n",
    "Convolution filter, 채널 개수, activation, 모델구조 수정가능\n",
    "\n",
    "만약 이 구성을 변경해 보면 어떤 효과가 발생하는지도 실험해 봅시다. BatchNormalization을 쓰거나 혹은 쓰지 않거나, Dropout을 쓰거나 혹은 쓰지 않거나 할 수 있습니다. 또, Dropout 비율을 변경해볼 수도 있습니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-cleaners",
   "metadata": {},
   "source": [
    "BatchNormalization: 레이어를 통과할때 입력값(w)의 분포가 각자 달라서 기울기 손실, exploding이 발생한다. 그래서 입력값을 일반화 해서 안정적이게 만듬\n",
    "\n",
    " 입력값 분포를 평균 0, 표준 편차 1인 분포로 만든다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(filters):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool2D()\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(units, dropout_rate):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        \n",
    "        conv_block(64),\n",
    "        conv_block(64),\n",
    "        \n",
    "        conv_block(128),\n",
    "        tf.keras.layers.Dropout(0.2), #오버피팅을 막기 위해서 노드를 랜덤하게 out\n",
    "        \n",
    "        conv_block(256),\n",
    "        tf.keras.layers.Dropout(0.2), \n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        dense_block(512, 0.7),\n",
    "        dense_block(128, 0.5),\n",
    "        dense_block(64, 0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-connection",
   "metadata": {},
   "source": [
    "# Step 5. 데이터 imbalance 처리\n",
    " recall을 강조하기 위해 폐렴데이터를 잘 맞추는 것을 더 강화하는 효과를 만들어낼 수는 없을까요? \n",
    " \n",
    " ### 클래스 균형은 소수의 클래스를 예측할때 중요하다.\n",
    " 소수의 클래스를 예측하는게 더 중요한 문제일때 그 클ㄹ스에 더 큰 비중(가중치)를 두고 정확하게 예측한다.\n",
    "\n",
    "training set의 데이터에서 loss를 계산할때 특정 클래스에 더 큰 loss값을 갖도록하여 가중치를 부여하는 방법이다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_for_0 = (1 / COUNT_NORMAL)*(TRAIN_IMG_COUNT)/2.0 \n",
    "weight_for_1 = (1 / COUNT_PNEUMONIA)*(TRAIN_IMG_COUNT)/2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-treatment",
   "metadata": {},
   "source": [
    "# Step 6. 모델 훈련\n",
    "optimizer나 learning rate 변경가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model = build_model()\n",
    "    model.summary()\n",
    "    \n",
    "    METRICS = [\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "    #모델 학습\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=METRICS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model = build_model()\n",
    "\n",
    "    METRICS = [\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=METRICS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        steps_per_epoch=TRAIN_IMG_COUNT // BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_ds,\n",
    "        validation_steps=VAL_IMG_COUNT // BATCH_SIZE,\n",
    "        class_weight=class_weight,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-cattle",
   "metadata": {},
   "source": [
    "# Step 7. 결과 확인과 시각화\n",
    " 훈련과정의 history 그래프를 시각화해 보고, 학습 진행양상을 면밀히 분석해 보는 것도 잊지 않도록 합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터로 모델평가\n",
    "loss, acc, prec, rec = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-exclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
